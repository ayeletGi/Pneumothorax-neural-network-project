{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import gc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "paths and globals definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'run this if you are working from google colab!!'"
            ]
          },
          "execution_count": 278,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"run this if you are working from google colab!!\"\"\"\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "# code_dir = \"/content/gdrive/MyDrive/neural network project\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"run this if you are working from your local computer!!\"\"\"\n",
        "code_dir = os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noXflhbhh0Za",
        "outputId": "e51dede0-ddd0-4112-c5da-08ca124763c1"
      },
      "outputs": [],
      "source": [
        "############## TENSORBOARD ########################\n",
        "writer = SummaryWriter(\"runs/PNEUMOTHORAX\")\n",
        "###################################################\n",
        "\n",
        "data_dir = os.path.join(code_dir, \"Data\")\n",
        "class_file_path = os.path.join(code_dir, \"train_data.csv\")\n",
        "\n",
        "PNEUMOTHORAX = 1\n",
        "NOT_PNEUMOTHORAX = 0\n",
        "classes = {PNEUMOTHORAX, NOT_PNEUMOTHORAX}\n",
        "num_classes = len(classes)\n",
        "\n",
        "classification_file = pd.read_csv(class_file_path, header=0)\n",
        "\n",
        "# Hyper-parameters\n",
        "batch_size = 8\n",
        "num_workers = 0\n",
        "epochs = 10\n",
        "learning_rate = 0.01\n",
        "image_size = 200\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gCbCaXHky8h"
      },
      "source": [
        "dataset definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 281,
      "metadata": {
        "id": "uvsp2Ex40qlg"
      },
      "outputs": [],
      "source": [
        "class PneumDataset(Dataset):\n",
        "    def __init__(self, data_path, images_paths, labels, transform):\n",
        "        # init custom dataset attributes\n",
        "        self.data_path = data_path\n",
        "        self.X_images = images_paths\n",
        "        self.y_labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        # len of the dataset\n",
        "        return len(self.X_images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # get specific sample by index\n",
        "        img_path = self.X_images[index]\n",
        "        label = self.y_labels[index]\n",
        "\n",
        "        # opening the image\n",
        "        path = os.path.join(self.data_path, img_path)\n",
        "        image = Image.open(path)\n",
        "        image = image.convert(\"RGB\")\n",
        "        \n",
        "        # converting x,y to tensors\n",
        "        image = self.transform(image)\n",
        "        label = torch.tensor(label, dtype=torch.long)\n",
        "        label = label.view(1)\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "loading and splitting the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 282,
      "metadata": {
        "id": "CvvlDg53hdVD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "One batch images shape: torch.Size([8, 3, 200, 200])\n",
            "One batch labels shape: torch.Size([8, 1])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "def imshow(img):\n",
        "    np_img = img.numpy()\n",
        "    plt.imshow(np.transpose(np_img, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "images_paths = np.asarray(classification_file[\"file_name\"])\n",
        "images_targets = np.asarray(classification_file[\"target\"])\n",
        "\n",
        "# split to train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(images_paths, images_targets, stratify=images_targets, random_state = 50)\n",
        "\n",
        "# transform\n",
        "transform = transforms.Compose([transforms.Resize(image_size),\n",
        "                                # transforms.CenterCrop(image_size - 10),\n",
        "                                transforms.ToTensor()])\n",
        "\n",
        "# create dataloaders\n",
        "train_dataset = PneumDataset(data_dir, X_train, y_train, transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                          shuffle=True, num_workers=num_workers)\n",
        "\n",
        "test_dataset = PneumDataset(data_dir, X_test, y_test, transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size,\n",
        "                         shuffle=False, num_workers=num_workers)\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "example_images, example_labels = dataiter.next()  # random batch\n",
        "\n",
        "# batch shapes\n",
        "print(f'One batch images shape: {example_images.shape}')\n",
        "print(f'One batch labels shape: {example_labels.shape}')\n",
        "\n",
        "# show images\n",
        "img_grid = torchvision.utils.make_grid(example_images)\n",
        "imshow(img_grid)\n",
        "\n",
        "############## TENSORBOARD ########################\n",
        "writer.add_image('PNEUMOTHORAX image grid', img_grid)\n",
        "###################################################\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLrWwGk-kwvU"
      },
      "source": [
        "model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 283,
      "metadata": {
        "id": "zV8exRkkidNp"
      },
      "outputs": [],
      "source": [
        "class PneumNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PneumNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=20)\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=20)\n",
        "        self.fc1 = nn.Linear(in_features =16*35*35, out_features=100 )\n",
        "        self.fc2 = nn.Linear(in_features=100, out_features = 50)\n",
        "        self.fc3 = nn.Linear(in_features=50, out_features=1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        # print(x.shape)\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        # print(x.shape)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        # print(x.shape)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        # print(x.shape)\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        # print(x.shape)\n",
        "        x = torch.sigmoid(self.fc3(x))\n",
        "        # print(x.shape)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVeED0cKuNO0"
      },
      "source": [
        "loss, optimizer definition "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 284,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working on device: cuda\n"
          ]
        }
      ],
      "source": [
        "# device\n",
        "device = \"cpu\"\n",
        "if (torch.cuda.is_available()):\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    device = \"cuda\"\n",
        "print(f\"Working on device: {device}\")\n",
        "\n",
        "# model\n",
        "model = PneumNet().to(device)\n",
        "\n",
        "# loss and optimizer\n",
        "criterion = nn.BCELoss()  # binary cross entropy\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "############## TENSORBOARD ########################\n",
        "writer.add_graph(model, example_images.to(device))\n",
        "###################################################\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdQYEufG5Ocu"
      },
      "source": [
        "train function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1755tyn45LjC",
        "outputId": "c54e8f0b-e113-4c2d-8e8c-f2d0dbdc0456"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "starting training\n",
            "Epoch [1/10], Step [10/190], Loss: 0.4213\n",
            "Epoch [1/10], Step [20/190], Loss: 0.7189\n",
            "Epoch [1/10], Step [30/190], Loss: 0.6838\n",
            "Epoch [1/10], Step [40/190], Loss: 0.5841\n",
            "Epoch [1/10], Step [50/190], Loss: 0.3575\n",
            "Epoch [1/10], Step [60/190], Loss: 0.3724\n",
            "Epoch [1/10], Step [70/190], Loss: 0.4075\n",
            "Epoch [1/10], Step [80/190], Loss: 0.9847\n",
            "Epoch [1/10], Step [90/190], Loss: 0.4551\n",
            "Epoch [1/10], Step [100/190], Loss: 0.7837\n",
            "Epoch [1/10], Step [110/190], Loss: 0.6112\n",
            "Epoch [1/10], Step [120/190], Loss: 0.3672\n",
            "Epoch [1/10], Step [130/190], Loss: 0.4023\n",
            "Epoch [1/10], Step [140/190], Loss: 0.6762\n",
            "Epoch [1/10], Step [150/190], Loss: 0.4038\n",
            "Epoch [1/10], Step [160/190], Loss: 0.3473\n",
            "Epoch [1/10], Step [170/190], Loss: 0.4613\n",
            "Epoch [1/10], Step [180/190], Loss: 0.4553\n",
            "Epoch [1/10], Step [190/190], Loss: 0.5469\n",
            "Epoch [2/10], Step [10/190], Loss: 0.3762\n",
            "Epoch [2/10], Step [20/190], Loss: 0.3970\n",
            "Epoch [2/10], Step [30/190], Loss: 0.6616\n",
            "Epoch [2/10], Step [40/190], Loss: 0.6462\n",
            "Epoch [2/10], Step [50/190], Loss: 0.3602\n",
            "Epoch [2/10], Step [60/190], Loss: 0.3092\n",
            "Epoch [2/10], Step [70/190], Loss: 0.5800\n",
            "Epoch [2/10], Step [80/190], Loss: 0.4258\n",
            "Epoch [2/10], Step [90/190], Loss: 0.6404\n",
            "Epoch [2/10], Step [100/190], Loss: 0.4963\n",
            "Epoch [2/10], Step [110/190], Loss: 0.5642\n",
            "Epoch [2/10], Step [120/190], Loss: 0.1954\n",
            "Epoch [2/10], Step [130/190], Loss: 0.5382\n",
            "Epoch [2/10], Step [140/190], Loss: 0.4577\n",
            "Epoch [2/10], Step [150/190], Loss: 0.4537\n",
            "Epoch [2/10], Step [160/190], Loss: 0.9689\n",
            "Epoch [2/10], Step [170/190], Loss: 0.6503\n",
            "Epoch [2/10], Step [180/190], Loss: 0.4760\n",
            "Epoch [2/10], Step [190/190], Loss: 1.2213\n",
            "Epoch [3/10], Step [10/190], Loss: 0.6616\n",
            "Epoch [3/10], Step [20/190], Loss: 0.4158\n",
            "Epoch [3/10], Step [30/190], Loss: 0.6192\n",
            "Epoch [3/10], Step [40/190], Loss: 0.5648\n",
            "Epoch [3/10], Step [50/190], Loss: 0.3452\n",
            "Epoch [3/10], Step [60/190], Loss: 0.8927\n",
            "Epoch [3/10], Step [70/190], Loss: 0.4262\n",
            "Epoch [3/10], Step [80/190], Loss: 0.1449\n",
            "Epoch [3/10], Step [90/190], Loss: 0.6063\n",
            "Epoch [3/10], Step [100/190], Loss: 0.4857\n",
            "Epoch [3/10], Step [110/190], Loss: 0.6888\n",
            "Epoch [3/10], Step [120/190], Loss: 0.4242\n",
            "Epoch [3/10], Step [130/190], Loss: 0.1131\n",
            "Epoch [3/10], Step [140/190], Loss: 0.5798\n",
            "Epoch [3/10], Step [150/190], Loss: 0.4446\n",
            "Epoch [3/10], Step [160/190], Loss: 0.7814\n",
            "Epoch [3/10], Step [170/190], Loss: 0.3645\n",
            "Epoch [3/10], Step [180/190], Loss: 0.4581\n",
            "Epoch [3/10], Step [190/190], Loss: 0.2443\n",
            "Epoch [4/10], Step [10/190], Loss: 0.5036\n",
            "Epoch [4/10], Step [20/190], Loss: 0.3915\n",
            "Epoch [4/10], Step [30/190], Loss: 0.1569\n",
            "Epoch [4/10], Step [40/190], Loss: 0.5531\n",
            "Epoch [4/10], Step [50/190], Loss: 0.4165\n",
            "Epoch [4/10], Step [60/190], Loss: 0.3782\n",
            "Epoch [4/10], Step [70/190], Loss: 0.6492\n",
            "Epoch [4/10], Step [80/190], Loss: 0.4189\n",
            "Epoch [4/10], Step [90/190], Loss: 0.6352\n",
            "Epoch [4/10], Step [100/190], Loss: 0.6585\n",
            "Epoch [4/10], Step [110/190], Loss: 0.5625\n",
            "Epoch [4/10], Step [120/190], Loss: 0.4207\n",
            "Epoch [4/10], Step [130/190], Loss: 0.6799\n",
            "Epoch [4/10], Step [140/190], Loss: 0.4069\n",
            "Epoch [4/10], Step [150/190], Loss: 0.4931\n",
            "Epoch [4/10], Step [160/190], Loss: 0.5714\n",
            "Epoch [4/10], Step [170/190], Loss: 0.5444\n",
            "Epoch [4/10], Step [180/190], Loss: 0.5906\n",
            "Epoch [4/10], Step [190/190], Loss: 0.5761\n",
            "Epoch [5/10], Step [10/190], Loss: 0.5648\n",
            "Epoch [5/10], Step [20/190], Loss: 0.7698\n",
            "Epoch [5/10], Step [30/190], Loss: 0.3529\n",
            "Epoch [5/10], Step [40/190], Loss: 0.2610\n",
            "Epoch [5/10], Step [50/190], Loss: 0.5176\n",
            "Epoch [5/10], Step [60/190], Loss: 0.5962\n",
            "Epoch [5/10], Step [70/190], Loss: 0.5494\n",
            "Epoch [5/10], Step [80/190], Loss: 0.6337\n",
            "Epoch [5/10], Step [90/190], Loss: 0.4633\n",
            "Epoch [5/10], Step [100/190], Loss: 0.5736\n",
            "Epoch [5/10], Step [110/190], Loss: 0.7324\n",
            "Epoch [5/10], Step [120/190], Loss: 0.7893\n",
            "Epoch [5/10], Step [130/190], Loss: 0.7091\n",
            "Epoch [5/10], Step [140/190], Loss: 0.4257\n",
            "Epoch [5/10], Step [150/190], Loss: 0.5939\n",
            "Epoch [5/10], Step [160/190], Loss: 0.4502\n",
            "Epoch [5/10], Step [170/190], Loss: 1.0437\n",
            "Epoch [5/10], Step [180/190], Loss: 0.5754\n",
            "Epoch [5/10], Step [190/190], Loss: 0.4279\n",
            "Epoch [6/10], Step [10/190], Loss: 0.3857\n",
            "Epoch [6/10], Step [20/190], Loss: 0.5498\n",
            "Epoch [6/10], Step [30/190], Loss: 0.5257\n",
            "Epoch [6/10], Step [40/190], Loss: 0.8364\n",
            "Epoch [6/10], Step [50/190], Loss: 0.4960\n",
            "Epoch [6/10], Step [60/190], Loss: 0.3710\n",
            "Epoch [6/10], Step [70/190], Loss: 0.0736\n",
            "Epoch [6/10], Step [80/190], Loss: 0.5615\n",
            "Epoch [6/10], Step [90/190], Loss: 0.3856\n",
            "Epoch [6/10], Step [100/190], Loss: 0.2703\n",
            "Epoch [6/10], Step [110/190], Loss: 0.7967\n",
            "Epoch [6/10], Step [120/190], Loss: 0.6653\n",
            "Epoch [6/10], Step [130/190], Loss: 0.5056\n",
            "Epoch [6/10], Step [140/190], Loss: 0.5786\n",
            "Epoch [6/10], Step [150/190], Loss: 0.6811\n",
            "Epoch [6/10], Step [160/190], Loss: 0.7471\n",
            "Epoch [6/10], Step [170/190], Loss: 0.6246\n",
            "Epoch [6/10], Step [180/190], Loss: 0.7169\n",
            "Epoch [6/10], Step [190/190], Loss: 0.7329\n",
            "Epoch [7/10], Step [10/190], Loss: 0.4340\n",
            "Epoch [7/10], Step [20/190], Loss: 0.3942\n",
            "Epoch [7/10], Step [30/190], Loss: 0.4717\n",
            "Epoch [7/10], Step [40/190], Loss: 0.4869\n",
            "Epoch [7/10], Step [50/190], Loss: 0.5328\n",
            "Epoch [7/10], Step [60/190], Loss: 0.6010\n",
            "Epoch [7/10], Step [70/190], Loss: 0.5989\n",
            "Epoch [7/10], Step [80/190], Loss: 0.3427\n",
            "Epoch [7/10], Step [90/190], Loss: 0.4723\n",
            "Epoch [7/10], Step [100/190], Loss: 0.3676\n",
            "Epoch [7/10], Step [110/190], Loss: 0.3612\n",
            "Epoch [7/10], Step [120/190], Loss: 0.3928\n",
            "Epoch [7/10], Step [130/190], Loss: 0.6446\n",
            "Epoch [7/10], Step [140/190], Loss: 0.5375\n",
            "Epoch [7/10], Step [150/190], Loss: 0.6172\n",
            "Epoch [7/10], Step [160/190], Loss: 0.6591\n",
            "Epoch [7/10], Step [170/190], Loss: 0.5448\n",
            "Epoch [7/10], Step [180/190], Loss: 0.3533\n",
            "Epoch [7/10], Step [190/190], Loss: 0.1188\n",
            "Epoch [8/10], Step [10/190], Loss: 0.5567\n",
            "Epoch [8/10], Step [20/190], Loss: 0.5463\n",
            "Epoch [8/10], Step [30/190], Loss: 0.4256\n",
            "Epoch [8/10], Step [40/190], Loss: 0.5671\n",
            "Epoch [8/10], Step [50/190], Loss: 0.5527\n",
            "Epoch [8/10], Step [60/190], Loss: 0.3871\n",
            "Epoch [8/10], Step [70/190], Loss: 0.7992\n",
            "Epoch [8/10], Step [80/190], Loss: 0.5534\n",
            "Epoch [8/10], Step [90/190], Loss: 0.5748\n",
            "Epoch [8/10], Step [100/190], Loss: 0.5992\n",
            "Epoch [8/10], Step [110/190], Loss: 1.2009\n",
            "Epoch [8/10], Step [120/190], Loss: 0.6752\n",
            "Epoch [8/10], Step [130/190], Loss: 0.3394\n",
            "Epoch [8/10], Step [140/190], Loss: 0.5427\n",
            "Epoch [8/10], Step [150/190], Loss: 0.6396\n",
            "Epoch [8/10], Step [160/190], Loss: 0.5515\n",
            "Epoch [8/10], Step [170/190], Loss: 0.7033\n",
            "Epoch [8/10], Step [180/190], Loss: 0.4415\n",
            "Epoch [8/10], Step [190/190], Loss: 0.3336\n",
            "Epoch [9/10], Step [10/190], Loss: 0.2497\n",
            "Epoch [9/10], Step [20/190], Loss: 0.5655\n",
            "Epoch [9/10], Step [30/190], Loss: 0.6492\n",
            "Epoch [9/10], Step [40/190], Loss: 0.1508\n",
            "Epoch [9/10], Step [50/190], Loss: 0.6750\n",
            "Epoch [9/10], Step [60/190], Loss: 0.4753\n",
            "Epoch [9/10], Step [70/190], Loss: 0.4485\n",
            "Epoch [9/10], Step [80/190], Loss: 0.2056\n",
            "Epoch [9/10], Step [90/190], Loss: 0.4418\n",
            "Epoch [9/10], Step [100/190], Loss: 0.3647\n",
            "Epoch [9/10], Step [110/190], Loss: 0.4023\n",
            "Epoch [9/10], Step [120/190], Loss: 0.3265\n",
            "Epoch [9/10], Step [130/190], Loss: 0.7671\n",
            "Epoch [9/10], Step [140/190], Loss: 0.6052\n",
            "Epoch [9/10], Step [150/190], Loss: 0.5061\n",
            "Epoch [9/10], Step [160/190], Loss: 0.5909\n",
            "Epoch [9/10], Step [170/190], Loss: 0.5947\n",
            "Epoch [9/10], Step [180/190], Loss: 0.6641\n",
            "Epoch [9/10], Step [190/190], Loss: 0.4217\n",
            "Epoch [10/10], Step [10/190], Loss: 0.6197\n",
            "Epoch [10/10], Step [20/190], Loss: 0.5695\n",
            "Epoch [10/10], Step [30/190], Loss: 0.4141\n",
            "Epoch [10/10], Step [40/190], Loss: 0.5619\n",
            "Epoch [10/10], Step [50/190], Loss: 0.5408\n",
            "Epoch [10/10], Step [60/190], Loss: 0.3679\n",
            "Epoch [10/10], Step [70/190], Loss: 0.7786\n",
            "Epoch [10/10], Step [80/190], Loss: 0.4413\n",
            "Epoch [10/10], Step [90/190], Loss: 0.5073\n",
            "Epoch [10/10], Step [100/190], Loss: 0.3299\n",
            "Epoch [10/10], Step [110/190], Loss: 0.4686\n",
            "Epoch [10/10], Step [120/190], Loss: 0.3887\n",
            "Epoch [10/10], Step [130/190], Loss: 0.7397\n",
            "Epoch [10/10], Step [140/190], Loss: 0.3483\n",
            "Epoch [10/10], Step [150/190], Loss: 0.4105\n",
            "Epoch [10/10], Step [160/190], Loss: 0.6602\n",
            "Epoch [10/10], Step [170/190], Loss: 0.6586\n",
            "Epoch [10/10], Step [180/190], Loss: 0.3697\n",
            "Epoch [10/10], Step [190/190], Loss: 0.7682\n"
          ]
        }
      ],
      "source": [
        "def train(data_loader, model, optimizer, device, epochs, samples_num):    \n",
        "    model.train()\n",
        "    \n",
        "    num_steps = len(train_loader)\n",
        "    running_loss = 0.0 \n",
        "    running_correct = 0.0\n",
        "    threshold = 0.6\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        for i, data in enumerate(data_loader):\n",
        "            (images, labels) = data\n",
        "            images = images.to(device, dtype=torch.float)\n",
        "            labels = labels.to(device, dtype=torch.float)\n",
        "\n",
        "            # Forward\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            predicted = outputs > threshold\n",
        "            running_loss += loss.item()\n",
        "            running_correct += (predicted == labels).sum().item()\n",
        "            \n",
        "            if (i+1) % 10 == 0:\n",
        "                print(f'Epoch [{epoch+1}/{epochs}], Step [{i+1}/{num_steps}], Loss: {loss.item():.4f}')\n",
        "                ############## TENSORBOARD ########################\n",
        "                writer.add_scalar('training loss', running_loss /\n",
        "                                  100, epoch * num_steps + i)\n",
        "                running_accuracy = running_correct / 100 / predicted.size(0)\n",
        "                writer.add_scalar('accuracy', running_accuracy,\n",
        "                                  epoch * num_steps + i)\n",
        "                running_correct = 0\n",
        "                running_loss = 0.0\n",
        "                ###################################################\n",
        "\n",
        "\n",
        "print(\"starting training\")\n",
        "train(train_loader, model, optimizer, device, epochs, len(train_dataset))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrLAap_Z9N4x"
      },
      "source": [
        "test function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhH32jFS9KxC",
        "outputId": "ad7b71d7-9088-4485-b48b-a72f6659e925"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 77.51479289940828 %\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "weights should have the same shape as a.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Input \u001b[1;32mIn [292]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m     labels_i \u001b[38;5;241m=\u001b[39m class_labels \u001b[38;5;241m==\u001b[39m i\n\u001b[0;32m     42\u001b[0m     preds_i \u001b[38;5;241m=\u001b[39m class_preds[:, i]\n\u001b[1;32m---> 43\u001b[0m     \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_pr_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreds_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m writer\u001b[38;5;241m.\u001b[39mclose()\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:881\u001b[0m, in \u001b[0;36mSummaryWriter.add_pr_curve\u001b[1;34m(self, tag, labels, predictions, global_step, num_thresholds, weights, walltime)\u001b[0m\n\u001b[0;32m    878\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_once(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard.logging.add_pr_curve\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    879\u001b[0m labels, predictions \u001b[38;5;241m=\u001b[39m make_np(labels), make_np(predictions)\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_file_writer()\u001b[38;5;241m.\u001b[39madd_summary(\n\u001b[1;32m--> 881\u001b[0m     \u001b[43mpr_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_thresholds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    882\u001b[0m     global_step, walltime)\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\tensorboard\\summary.py:589\u001b[0m, in \u001b[0;36mpr_curve\u001b[1;34m(tag, labels, predictions, num_thresholds, weights)\u001b[0m\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpr_curve\u001b[39m(tag, labels, predictions, num_thresholds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m127\u001b[39m, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    587\u001b[0m     \u001b[38;5;66;03m# weird, value > 127 breaks protobuf\u001b[39;00m\n\u001b[0;32m    588\u001b[0m     num_thresholds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(num_thresholds, \u001b[38;5;241m127\u001b[39m)\n\u001b[1;32m--> 589\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mnum_thresholds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_thresholds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m     pr_curve_plugin_data \u001b[38;5;241m=\u001b[39m PrCurvePluginData(\n\u001b[0;32m    592\u001b[0m         version\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, num_thresholds\u001b[38;5;241m=\u001b[39mnum_thresholds)\u001b[38;5;241m.\u001b[39mSerializeToString()\n\u001b[0;32m    593\u001b[0m     plugin_data \u001b[38;5;241m=\u001b[39m SummaryMetadata\u001b[38;5;241m.\u001b[39mPluginData(\n\u001b[0;32m    594\u001b[0m         plugin_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpr_curves\u001b[39m\u001b[38;5;124m'\u001b[39m, content\u001b[38;5;241m=\u001b[39mpr_curve_plugin_data)\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\tensorboard\\summary.py:614\u001b[0m, in \u001b[0;36mcompute_curve\u001b[1;34m(labels, predictions, num_thresholds, weights)\u001b[0m\n\u001b[0;32m    612\u001b[0m float_labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    613\u001b[0m histogram_range \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, num_thresholds \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 614\u001b[0m tp_buckets, _ \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistogram\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbucket_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_thresholds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistogram_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfloat_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    619\u001b[0m fp_buckets, _ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhistogram(\n\u001b[0;32m    620\u001b[0m     bucket_indices,\n\u001b[0;32m    621\u001b[0m     bins\u001b[38;5;241m=\u001b[39mnum_thresholds,\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28mrange\u001b[39m\u001b[38;5;241m=\u001b[39mhistogram_range,\n\u001b[0;32m    623\u001b[0m     weights\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m float_labels) \u001b[38;5;241m*\u001b[39m weights)\n\u001b[0;32m    625\u001b[0m \u001b[38;5;66;03m# Obtain the reverse cumulative sum.\u001b[39;00m\n",
            "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mhistogram\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\histograms.py:791\u001b[0m, in \u001b[0;36mhistogram\u001b[1;34m(a, bins, range, normed, weights, density)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_histogram_dispatcher)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhistogram\u001b[39m(a, bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, \u001b[38;5;28mrange\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    680\u001b[0m               density\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    681\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;124;03m    Compute the histogram of a dataset.\u001b[39;00m\n\u001b[0;32m    683\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    789\u001b[0m \n\u001b[0;32m    790\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 791\u001b[0m     a, weights \u001b[38;5;241m=\u001b[39m \u001b[43m_ravel_and_check_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    793\u001b[0m     bin_edges, uniform_bins \u001b[38;5;241m=\u001b[39m _get_bin_edges(a, bins, \u001b[38;5;28mrange\u001b[39m, weights)\n\u001b[0;32m    795\u001b[0m     \u001b[38;5;66;03m# Histogram is an integer or a float array depending on the weights.\u001b[39;00m\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\histograms.py:297\u001b[0m, in \u001b[0;36m_ravel_and_check_weights\u001b[1;34m(a, weights)\u001b[0m\n\u001b[0;32m    295\u001b[0m     weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(weights)\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weights\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m a\u001b[38;5;241m.\u001b[39mshape:\n\u001b[1;32m--> 297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    298\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights should have the same shape as a.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    299\u001b[0m     weights \u001b[38;5;241m=\u001b[39m weights\u001b[38;5;241m.\u001b[39mravel()\n\u001b[0;32m    300\u001b[0m a \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mravel()\n",
            "\u001b[1;31mValueError\u001b[0m: weights should have the same shape as a."
          ]
        }
      ],
      "source": [
        "def test(data_loader, model, device):\n",
        "    model.eval()\n",
        "    # init lists to store targets and outputs\n",
        "    class_labels = []\n",
        "    class_preds = []\n",
        "    threshold = 0.6\n",
        "    # no_grad context\n",
        "    with torch.no_grad():\n",
        "        n_correct = 0\n",
        "        n_samples = 0\n",
        "        for data in data_loader:\n",
        "            (images, labels) = data\n",
        "\n",
        "            images = images.to(device, dtype=torch.float)\n",
        "            labels = labels.to(device, dtype=torch.float)\n",
        "\n",
        "            # predict\n",
        "            outputs = model(images)\n",
        "            \n",
        "            predicted = outputs > threshold\n",
        "            n_samples += labels.size(0)\n",
        "            n_correct += (predicted == labels).sum().item()\n",
        "            \n",
        "            class_preds.append(outputs)\n",
        "            class_labels.append(predicted)\n",
        "            \n",
        "    return class_preds, class_labels, n_samples, n_correct\n",
        "\n",
        "\n",
        "class_preds, class_labels, n_samples, n_correct = test(test_loader, model, device=device)\n",
        "\n",
        "class_preds = torch.cat(class_preds)\n",
        "class_labels = torch.cat(class_labels)\n",
        "\n",
        "acc = 100.0 * n_correct / n_samples\n",
        "print(f'Accuracy of the network on the 10000 test images: {acc} %')\n",
        "\n",
        "\n",
        "############## TENSORBOARD ########################\n",
        "for i in classes:\n",
        "    labels_i = class_labels == i\n",
        "    preds_i = class_preds[:, i]\n",
        "    writer.add_pr_curve(str(i), labels_i, preds_i, global_step=0)\n",
        "writer.close()\n",
        "###################################################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUAQ7b4158KT"
      },
      "outputs": [],
      "source": [
        "# def split_data():\n",
        "#     \"\"\"\n",
        "#     ONLY RUN ONCE!!!\n",
        "#     split the data to 2 class directory using the information from the data file\n",
        "#     \"\"\"\n",
        "\n",
        "#     for row, file_name in enumerate(classification_file[\"file_name\"]):\n",
        "#       lable = classification_file[\"target\"][row]\n",
        "#       original_path = os.path.join(data_dir, file_name)\n",
        "      \n",
        "#       if lable == PENUMOTHORAX:\n",
        "#         dest_path = os.path.join(Pneumothorax_dir, file_name)\n",
        "#       elif lable == NOT_PENUMOTHORAX:\n",
        "#         dest_path = os.path.join(not_Pneumothorax_dir, file_name)\n",
        "\n",
        "#       shutil.copy(original_path,dest_path)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpJNLI3GhAof"
      },
      "outputs": [],
      "source": [
        "# # Train and evaluate functions \n",
        "\n",
        "# def train(data_loader, model, optimizer, device):\n",
        "#     \"\"\"\n",
        "#     training for one epoch with selected model and params\n",
        "#      data_loader:  pytorch dataloader\n",
        "#      model: pytorch model\n",
        "#      optimizer: optimizer \n",
        "#      device: cuda/cpu\n",
        "#     \"\"\"\n",
        "#     # set training mode \n",
        "#     model.train()\n",
        "#     # go over every batch of data in data loader\n",
        "#     for data in data_loader:\n",
        "#         inputs = data[\"image\"]\n",
        "#         targets = data[\"targets\"]\n",
        "#         # move inputs/targets to cuda/cpu device\n",
        "#         inputs = inputs.to(device, dtype=torch.float)\n",
        "#         targets = targets.to(device, dtype=torch.float)\n",
        "#         # zero grad the optimizer\n",
        "#         optimizer.zero_grad()\n",
        "#         # do the forward step of model\n",
        "#         outputs = model(inputs)\n",
        "#         # calculate loss\n",
        "#         loss = nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))\n",
        "#         # backward step the loss\n",
        "#         loss.backward()\n",
        "#         # step optimizer\n",
        "#         optimizer.step()\n",
        "        \n",
        "# def evaluate(data_loader, model, device):\n",
        "#     \"\"\"\n",
        "#     Evaluation for one epoch\n",
        "#     data_loader: this is the pytorch dataloader\n",
        "#     model: pytorch model\n",
        "#     device: cuda/cpu\n",
        "#     \"\"\"\n",
        "#     # put model in evaluation mode\n",
        "#     model.eval()\n",
        "#     # init lists to store targets and outputs\n",
        "#     final_targets = []\n",
        "#     final_outputs = []\n",
        "#     # no_grad context\n",
        "#     with torch.no_grad():\n",
        "#         for data in data_loader:\n",
        "#             inputs = data[\"image\"]\n",
        "#             targets = data[\"targets\"]\n",
        "#             inputs = inputs.to(device, dtype=torch.float)\n",
        "#             targets = targets.to(device, dtype=torch.float)\n",
        "#             # generate prediction\n",
        "#             output = model(inputs)\n",
        "#             # convert targets and outputs to lists\n",
        "#             targets = targets.detach().cpu().numpy().tolist()\n",
        "#             output = output.detach().cpu().numpy().tolist()\n",
        "#             # extend the original list\n",
        "#             final_targets.extend(targets)\n",
        "#             final_outputs.extend(output)\n",
        "            \n",
        "#     return final_outputs, final_targets\n",
        "# # train and print auc score for all epochs\n",
        "# for epoch in tqdm(range(EPOCHS)):\n",
        "#     # train \n",
        "#     train(train_loader, model, optimizer, device=device)\n",
        "#     # predict \n",
        "#     predictions, valid_targets = evaluate(valid_loader, model, device=device)\n",
        "#     # metrics \n",
        "#     roc_auc = metrics.roc_auc_score(valid_targets, predictions)\n",
        "#     print(f\"Epoch={epoch}, Valid ROC AUC={roc_auc}\")\n",
        "\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "neural network project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
